# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax)) %>%
mutate(Date = as.Date(Date))  # âœ… Ensure Date class stays intact
# Step 4a: Decompose time series (MERGE = TRUE for time_recompose)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = TRUE)
# Step 4b: Detect anomalies
anomalized <- decomposed %>%
anomalize(remainder, Date)
library(readr)
library(dplyr)
library(anomalize)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax)) %>%
mutate(Date = as.Date(Date))  # âœ… Ensure Date class stays intact
# Step 4a: Decompose time series (MERGE = TRUE for time_recompose)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = TRUE)
# Step 4b: Ensure tbl_time format before anomalize
anomalized <- decomposed %>%
as_tbl_time(index = Date) %>%       # ðŸ”§ Fix: reapply time-based index
anomalize(remainder, Date)
library(readr)
library(dplyr)
library(anomalize)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax)) %>%
mutate(Date = as.Date(Date))  # âœ… Ensure Date class stays intact
# Step 4a: Decompose
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = TRUE)
# Step 4b: Fix for anomaly detection
anomalized <- decomposed %>%
as_tbl_time(index = Date) %>%
anomalize(remainder, Date)
library(readr)
library(dplyr)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values by interpolation
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax))
# Step 4a: Decompose the time series (merge = FALSE for manual handling)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = FALSE)
# Step 4b: Detect anomalies using IQR method on remainder
iqr_vals <- quantile(decomposed$remainder, probs = c(0.25, 0.75), na.rm = TRUE)
Q1 <- iqr_vals[1]
Q3 <- iqr_vals[2]
IQR <- Q3 - Q1
decomposed <- decomposed %>%
mutate(
anomaly = case_when(
remainder < Q1 - 1.5 * IQR ~ "Yes",
remainder > Q3 + 1.5 * IQR ~ "Yes",
TRUE ~ "No"
)
)
# Step 5: Extract anomalies
alerts <- decomposed %>%
filter(anomaly == "Yes") %>%
mutate(
year = year(Date),
temperature = observed
) %>%
select(year, temperature, Date, anomaly)
# Step 6: Save anomalies to CSV
write_csv(alerts, "alerts.csv")
# Step 7: Print sample anomalies
print(head(alerts))
plumber::plumb(file='alerts.R')$run()
library(readr)
library(dplyr)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values by interpolation
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax))
# Step 4a: Decompose the time series (merge = FALSE for manual handling)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = FALSE)
# Step 4b: Detect anomalies using IQR method on remainder
iqr_vals <- quantile(decomposed$remainder, probs = c(0.25, 0.75), na.rm = TRUE)
Q1 <- iqr_vals[1]
Q3 <- iqr_vals[2]
IQR <- Q3 - Q1
decomposed <- decomposed %>%
mutate(
anomaly = case_when(
remainder < Q1 - 1.5 * IQR ~ "Yes",
remainder > Q3 + 1.5 * IQR ~ "Yes",
TRUE ~ "No"
)
)
# Step 5: Extract anomalies
alerts <- decomposed %>%
filter(anomaly == "Yes") %>%
mutate(
year = year(Date),
temperature = observed
) %>%
select(year, temperature, Date, anomaly)
# Step 6: Save anomalies to CSV
write_csv(alerts, "alerts.csv")
# Step 7: Print sample anomalies
print(head(alerts))
plumb(file='alerts.R')$run()
plumber::plumb(file='alerts.R')$run()
library(readr)
library(dplyr)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values by interpolation
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax))
# Step 4a: Decompose the time series (merge = FALSE for manual handling)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = FALSE)
# Fit forecast model on historical TempMax
fit <- auto.arima(climate_tbl$TempMax)
library(readr)
library(dplyr)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values by interpolation
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax))
# Step 4a: Decompose the time series (merge = FALSE for manual handling)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = FALSE)
library(readr)
library(dplyr)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values by interpolation
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax))
# Step 4a: Decompose the time series (merge = FALSE for manual handling)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = FALSE)
library(readr)
library(dplyr)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
library(forecast)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values by interpolation
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax))
# Step 4a: Decompose the time series (merge = FALSE for manual handling)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = FALSE)
install.packages("anomalize")
library(readr)
library(dplyr)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
library(forecast)
library(anomalize)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values by interpolation
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax))
# Step 4a: Decompose the time series (merge = FALSE for manual handling)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = FALSE)
# Step 4b: Detect anomalies using IQR method on remainder
iqr_vals <- quantile(decomposed$remainder, probs = c(0.25, 0.75), na.rm = TRUE)
Q1 <- iqr_vals[1]
Q3 <- iqr_vals[2]
IQR <- Q3 - Q1
decomposed <- decomposed %>%
mutate(
anomaly = case_when(
remainder < Q1 - 1.5 * IQR ~ "Yes",
remainder > Q3 + 1.5 * IQR ~ "Yes",
TRUE ~ "No"
)
)
# Step 5: Extract historical anomalies
alerts <- decomposed %>%
filter(anomaly == "Yes") %>%
mutate(
year = year(Date),
temperature = observed
) %>%
select(year, temperature, Date, anomaly)
# Step 6: Forecast future temperature for 2025
fit <- auto.arima(climate_tbl$TempMax)
future <- forecast(fit, h = 365)
future_dates <- seq(max(climate_tbl$Date) + 1, by = "day", length.out = 365)
future_alerts <- data.frame(
Date = future_dates,
temperature = as.numeric(future$mean),
year = as.numeric(format(future_dates, "%Y")),
anomaly = "Yes"
) %>%
filter(year == 2025)  # Only keep 2025 forecasts
# Step 7: Combine historical and forecasted anomalies
final_alerts <- bind_rows(alerts, future_alerts)
# Step 8: Save combined alerts to CSV
write_csv(final_alerts, "alerts.csv")
# Step 9: Print sample anomalies
print(head(final_alerts))
plumber::plumb(file='alerts.R')$run()
library(readr)
library(dplyr)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
library(forecast)
library(anomalize)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values by interpolation
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax))
# Step 4a: Decompose the time series (merge = FALSE for manual handling)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = FALSE)
# Step 4b: Detect anomalies using IQR method on remainder
iqr_vals <- quantile(decomposed$remainder, probs = c(0.25, 0.75), na.rm = TRUE)
Q1 <- iqr_vals[1]
Q3 <- iqr_vals[2]
IQR <- Q3 - Q1
multiplier <- 3
decomposed <- decomposed %>%
mutate(
anomaly = case_when(
remainder < Q1 - multiplier * IQR ~ "Yes",
remainder > Q3 + multiplier * IQR ~ "Yes",
TRUE ~ "No"
)
)
# Step 5: Extract historical anomalies
alerts <- decomposed %>%
filter(anomaly == "Yes") %>%
mutate(
magnitude = abs(remainder),
year = year(Date),
temperature = observed
) %>%
arrange(desc(magnitude)) %>%
slice_head(n = 4) %>%
select(year, temperature, Date, anomaly)
# Step 6: Forecast future temperature for 2025
fit <- auto.arima(climate_tbl$TempMax)
future <- forecast(fit, h = 365)
future_dates <- seq(max(climate_tbl$Date) + 1, by = "day", length.out = 365)
future_alerts <- data.frame(
Date = future_dates,
temperature = as.numeric(future$mean),
year = as.numeric(format(future_dates, "%Y")),
anomaly = "Yes"
) %>%
filter(year == 2025)  # Only keep 2025 forecasts
# Step 7: Combine historical and forecasted anomalies
final_alerts <- bind_rows(alerts, future_alerts)
# Step 8: Save combined alerts to CSV
write_csv(final_alerts, "alerts.csv")
# Step 9: Print sample anomalies
print(head(final_alerts))
library(readr)
library(dplyr)
library(tibbletime)
library(timetk)
library(lubridate)
library(imputeTS)
library(forecast)
library(anomalize)
# Step 1: Load and clean the data
climate_data <- read_csv("cleaned_climate_data.csv") %>%
rename(TempMax = `TempMax(Â°C)`) %>%
mutate(Date = mdy(Date)) %>%
filter(!is.na(Date)) %>%
select(Date, TempMax) %>%
group_by(Date) %>%
summarise(TempMax = mean(TempMax, na.rm = TRUE)) %>%
ungroup() %>%
arrange(Date)
# Step 2: Convert to tbl_time and pad missing days
climate_tbl <- climate_data %>%
as_tbl_time(index = Date) %>%
pad_by_time(.date_var = Date, .by = "day") %>%
arrange(Date)
# Step 3: Impute missing TempMax values by interpolation
climate_tbl <- climate_tbl %>%
mutate(TempMax = na_interpolation(TempMax))
# Step 4a: Decompose the time series (merge = FALSE for manual handling)
decomposed <- climate_tbl %>%
time_decompose(TempMax, method = "stl", merge = FALSE)
# Step 4b: Detect anomalies using IQR method on remainder
iqr_vals <- quantile(decomposed$remainder, probs = c(0.25, 0.75), na.rm = TRUE)
Q1 <- iqr_vals[1]
Q3 <- iqr_vals[2]
IQR <- Q3 - Q1
multiplier <- 3
decomposed <- decomposed %>%
mutate(
anomaly = case_when(
remainder < Q1 - multiplier * IQR ~ "Yes",
remainder > Q3 + multiplier * IQR ~ "Yes",
TRUE ~ "No"
)
)
# Step 5: Extract historical anomalies
alerts <- decomposed %>%
filter(anomaly == "Yes") %>%
mutate(
magnitude = abs(remainder),
year = year(Date),
temperature = observed
) %>%
arrange(desc(magnitude)) %>%
slice_head(n = 4) %>%
select(year, temperature, Date, anomaly)
# Step 6: Forecast future temperature for 2025
fit <- auto.arima(climate_tbl$TempMax)
future <- forecast(fit, h = 365)
future_dates <- seq(max(climate_tbl$Date) + 1, by = "day", length.out = 365)
future_alerts <- data.frame(
Date = future_dates,
temperature = as.numeric(future$mean),
year = as.numeric(format(future_dates, "%Y")),
anomaly = "Yes"
) %>%
filter(year == 2025) %>%
arrange(desc(temperature)) %>%   # Sort by temperature descending (strongest anomalies)
slice_head(n = 4)                # Keep top 4 only
# Step 7: Combine historical and forecasted anomalies
final_alerts <- bind_rows(alerts, future_alerts)
# Step 8: Save combined alerts to CSV
write_csv(final_alerts, "alerts.csv")
# Step 9: Print sample anomalies
print(final_alerts)
